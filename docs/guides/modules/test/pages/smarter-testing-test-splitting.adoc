= Dynamic Test Distribution
:page-description: Evenly distribute tests across parallel execution nodes

Dynamic Test Distribution intelligently splits your tests across parallel execution nodes to minimize overall test execution time. The system maintains a shared queue that each node pulls from to create a balanced workload.

== How it works

When you configure parallelism in your job and enable dynamic test splitting, Smarter Testing automatically:

* Retrieves timing data from previous test runs.
* Uses the previous test run times as a heuristic to guide the order that tests are enqueued. Longer tests will be run earlier in the process.
* Tunes the size of the test batches run by each node to ensure the workload is evenly balanced.

This approach prevents slower nodes from extending the job runtime while other nodes have finished. All nodes continue to run tests until the entire test suite has been completed.

[mermaid]
----
flowchart LR
    discover(Discover \n A B C D E F G H I J)
    discover --> split1(Node 1 \n A... B..\n.........)
    discover --> split2(Node 2 \n C...... \n .......)
    discover --> split3(Node 3 \n D...... \n .. E...)
    subgraph "Dynamic Test Distribution"
    split1
    split2
    split3
    end
----

== Prerequisites

Before enabling Dynamic Test Distribution, ensure you have completed the xref:getting-started.adoc[Getting Started] guide and have:

* Installed the `testsuite` CLI plugin
* Configured your `.circleci/test-suites.yml` with `discover` and `run` commands
* Verified your tests run successfully with the `testsuite` command

== Enable Dynamic Test Distribution

Dynamic Test Distribution is automatically enabled when you use the `testsuite` command with parallelism configured in your CircleCI job.

=== 1. Configure parallelism in your CircleCI job

Update your `.circleci/config.yml` to add parallelism to your test job:

[source,yaml]
----
version: 2.1
jobs:
  test:
    executor: node-with-service
    parallelism: 4  # Run tests across 4 parallel nodes
    steps:
      - setup
      - run: circleci run testsuite "ci tests"
      - store_test_results:
          path: test-reports
----

=== 2. Verify timing data is being used

When you run your test suite with parallelism, look for indicators in the build output that timing data is being used to sort tests:

[source,console]
----
Discovering...
Discovered 100 tests in 250ms

Selecting tests...
Selected 100 tests, Skipped 0 tests in 5ms

Autodetected filename timings for 95 tests
Sorted tests in 10ms

Running tests across 4 nodes...
----

The message `Autodetected filename timings for N tests` indicates that historical timing data was found and is being used to optimize test distribution.

== How timing data works

Dynamic Test Distribution uses historical test timing data from previous runs to optimize distribution:

* **First run**: Tests run in discovery order since no timing data exists yet.
* **Subsequent runs**: Tests are sorted by duration (longest first) and distributed to minimize total execution time.
* **Timing sources**: The system automatically detects timing data from JUnit XML files stored via `store_test_results`.

The system looks for timing data in this priority order:

1. Filename-based timings
2. Classname-based timings
3. Testname-based timings

== Configuration options

=== Adjust batch sizing behavior

By default, Dynamic Test Distribution uses a queue-based approach where nodes fetch dynamic batches of tests. This ensures even workload distribution even when some nodes start slower or take longer than expected.

However, if your test runner has significant startup overhead, you can disable dynamic batching:

[source,yaml]
----
# .circleci/test-suites.yml
---
name: ci tests
discover: vitest list --filesOnly
run: vitest run --reporter=junit --outputFile="<< outputs.junit >>" --bail 0 << test.atoms >>
outputs:
  junit: test-reports/tests.xml
options:
  dynamic-test-splitting: false  # Disable queue-based splitting
----

When `dynamic-test-splitting: false`, tests are distributed statically across nodes at the start, which may be faster for test runners with high per-batch startup costs.

=== Combine with Test Impact Analysis

Dynamic Test Distribution works seamlessly with xref:test-impact-analysis.adoc[Test Impact Analysis]. When both features are enabled:

1. Test Impact Analysis selects which tests to run based on code changes
2. Dynamic Test Distribution distributes the selected tests across parallel nodes

[source,yaml]
----
# .circleci/test-suites.yml
---
name: ci tests
discover: vitest list --filesOnly
run: vitest run --reporter=junit --outputFile="<< outputs.junit >>" --bail 0 << test.atoms >>
analysis: |
  vitest run --coverage.enabled \
             --coverage.all=false \
             --coverage.reporter=lcov \
             --coverage.provider=v8 \
             --coverage.reportsDirectory="$(dirname << outputs.lcov >>)" \
             --silent \
             --bail 0 \
             << test.atoms >> \
             && cat "$(dirname << outputs.lcov >>)"/*.info > << outputs.lcov >>
outputs:
  junit: test-reports/tests.xml
options:
  test-impact-analysis: true
  dynamic-test-splitting: true
----

== Troubleshooting

=== Tests not being split evenly across nodes

*Symptoms:* Some parallel nodes finish much faster than others, or tests are not distributed evenly.

*Solution:* Verify that your test suite configuration includes historical timing data and that all test files are being detected. Check the step output for the "Sorted X tests" or "Autodetected timing" messages to confirm that test atoms are being sorted by timing.

*Debugging steps:*

1. Check that all test atoms are discovered with the discover command.
2. Verify parallelism is set correctly in your `.circleci/config.yml`.
3. Ensure test results are being stored with `store_test_results` - this is how timing data is collected.
4. Run the job multiple times to allow timing data to accumulate.

=== No timing data detected

*Symptoms:* Output shows "Timing data is not present" or no timing messages appear.

*Solution:* Ensure you're storing test results properly:

1. Verify `outputs.junit` in your `.circleci/test-suites.yml` points to the correct location
2. Confirm the `store_test_results` step in your `.circleci/config.yml` points to the directory containing your JUnit XML files
3. Check that your test runner is generating JUnit XML output with timing information

[source,yaml]
----
# .circleci/config.yml
jobs:
  test:
    steps:
      - run: circleci run testsuite "ci tests"
      - store_test_results:
          path: test-reports  # Must match outputs.junit directory
----

=== Some CI nodes are taking longer to run tests

*Symptoms:* Most nodes finish quickly, but one or two nodes take significantly longer.

*Explanation:* Dynamic Test Distribution uses a single queue for all parallel nodes, with each node fetching a dynamic batch size of tests to run. At the start of the queue, the batch size is large and becomes smaller as the queue empties. This batching from the queue allows all tests to be evenly distributed across nodes, ensuring that all nodes get evenly balanced work, even when some nodes have slow start up or take longer than expected to run tests.

*Solution:* Some test runners and language runtimes can have a reasonably large overhead getting to the point where they can start running tests. This interacts poorly with queue-based Dynamic Test Distribution.

If you're experiencing this issue, try disabling dynamic batching:

[source,yaml]
----
# .circleci/test-suites.yml
---
name: ci tests
discover: vitest list --filesOnly
run: vitest run --reporter=junit --outputFile="<< outputs.junit >>" --bail 0 << test.atoms >>
outputs:
  junit: test-reports/tests.xml
options:
  dynamic-test-splitting: false
----

This will pre-distribute tests to nodes at the start rather than using a dynamic queue, which can be faster when test runner startup is expensive.

=== Parallelism not utilizing all nodes

*Symptoms:* Some nodes don't receive any tests, or nodes are idle while tests are still running.

*Solution:* This usually happens when there are fewer tests than parallel nodes. Consider:

1. Reducing the parallelism value to match your typical test count after test selection
2. Using conditional parallelism based on branch (higher parallelism on branches that run all tests)

[source,yaml]
----
# .circleci/config.yml
version: 2.1
jobs:
  test:
    executor: node-with-service
    # Use more parallelism on main branch where all tests run
    parallelism: << pipeline.git.branch == "main" and 10 or 4 >>
    steps:
      - setup
      - run: circleci run testsuite "ci tests"
      - store_test_results:
          path: test-reports
----

== Frequently Asked Questions

=== How many parallel nodes should I use?

The optimal number depends on several factors:

* **Total test suite duration**: More parallelism helps longer test suites
* **Number of tests**: Diminishing returns when nodes > test count
* **CI plan limits**: Check your CircleCI plan for parallelism limits
* **Cost vs. speed tradeoff**: More nodes = faster but higher cost

A good starting point is to divide your total test duration by your target duration:
- Test suite takes 20 minutes, target 5 minutes → try 4 nodes
- Test suite takes 60 minutes, target 10 minutes → try 6 nodes

Start conservative and increase parallelism if needed.

=== How does Dynamic Test Distribution work with Test Impact Analysis?

They work together seamlessly:

1. **Test Impact Analysis** first selects which tests should run based on code changes
2. **Dynamic Test Distribution** then splits those selected tests across parallel nodes

For example:
- You have 100 total tests across 4 nodes
- Test Impact Analysis selects 30 tests based on your changes
- Dynamic Test Distribution splits those 30 tests across the 4 nodes (~7-8 per node)

This combination gives you both intelligent test selection and optimal distribution.

=== Does Dynamic Test Distribution require Test Impact Analysis?

No, Dynamic Test Distribution works independently:

* **With Test Impact Analysis**: Distributes the selected subset of tests
* **Without Test Impact Analysis**: Distributes all discovered tests

You can enable Dynamic Test Distribution by simply using the `testsuite` command with parallelism, regardless of whether Test Impact Analysis is configured.

=== How do I know if Dynamic Test Distribution is working?

Look for these indicators in your CircleCI build output:

Historical timing data is being found and used to order test execution:

* `Autodetected filename timings for N tests`
* `Autodetected classname timings for N tests`
* `Autodetected testname timings for N tests`
* `Sorted tests in Xms`

You should also see relatively even test execution times across all parallel nodes in the CircleCI UI.

=== Why is the first run slower than expected?

The first run has no historical timing data, so tests are distributed in discovery order rather than by duration. This may lead to uneven distribution.

After the first run:
1. Timing data is collected from JUnit XML files
2. Subsequent runs use this data to optimize distribution
3. Distribution improves as more timing data accumulates

=== Can I use Dynamic Test Distribution locally?

Yes! When you run `circleci run testsuite "ci tests" --local`, the system uses any available timing data from previous local runs or from CircleCI.

However, parallelism is a CircleCI feature that requires multiple execution nodes, so local runs execute tests sequentially. Dynamic Test Distribution will still sort tests by duration locally, but won't split them across multiple nodes.

=== What happens if a node fails or times out?

When a node fails:
* Other nodes continue processing tests from the queue
* The failed node's incomplete tests are not automatically retried on other nodes
* The job will be marked as failed

To handle flaky tests that cause node failures, consider enabling xref:auto-rerun-failed-tests.adoc[Auto Rerun Failed Tests].
