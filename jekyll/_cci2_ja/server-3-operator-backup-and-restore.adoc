---
version:
- Server v3.x
- Server Admin
---
= CircleCI Server v3.x Backup and Restore
:page-layout: classic-docs
:imagesdir: ../assets/img/docs/
:page-liquid:
:page-description: This document outlines recommendations for how to back up and restore your CircleCI server instance data and state.
:icons: font
:toc: macro
:toc-title:

toc::[]

== 概要
_バックアップと復元は、CircleCI Server v3.1.0 以上で利用できます。_

While operating and administering CircleCI server, you will need to consider how to maintain backups and recover your installation, should there be a need to migrate it to another cluster or recover from a critical event.

このドキュメントでは、CircleCI Server インスタンスのデータと状態のバックアップを行い復元する方法に関する推奨事項を説明します。

CircleCI server is administered via https://kots.io/[KOTS], which uses https://velero.io/[Velero] for backup and restore. この方法のメリットは、アプリケーションのデータだけでなく、バックアップ時点の Kubernetes クラスタの状態とリソースも復元することです。
This means you can also restore Admin Console configurations and customizations you made to your cluster. 

NOTE: CircleCI サービスのバックアップと復元は、Velero に依存しています。 If your cluster is lost, you will not be able to restore CircleCI until you have successfully started Velero in the cluster. Velero が正常に起動すれば、CircleCI サービスを復元できます。

== セットアップ

CircleCI Server のバックアップは、 https://kots.io/[KOTS] を介して作成できます。
However, to enable backup support you need to install and configure https://velero.io/[Velero] on your cluster.

以下のセクションでは、クラスタへの Velero のインストール手順を説明します。

=== 前提条件

- お使いの環境に合った https://velero.io/docs/v1.6/basic-install/[Velero CLI] をダウンロードしてインストールします。

==== AWS prerequisites

- https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html[AWS CLI] をインストール済みであること。

==== GCP prerequisites

- `gcloud` と `gsutil` をインストール済みであること。 これらは両方とも Google Cloud SDK に含まれており、SDK をインストールすることでセットアップできます (https://cloud.google.com/sdk/docs/[こちらのドキュメント]を参照してください)。

詳細については、Velero のhttps://velero.io/docs/v1.6/supported-providers/[[サポート対象プロバイダーに関するページ]]を参照してください。

以下で、AWS と GCP のそれぞれで CircleCI Server 3.x のバックアップを作成する手順について説明します。

==== S3-compatible storage prerequisites

- https://docs.min.io/docs/minio-client-quickstart-guide.html[MinIO CLI] is installed and configured for your storage provider.

////

* AWS SETUP *

////
== AWS での CircleCI Server 3.x のバックアップ

以下の手順では、プロバイダーが AWS であり、上記の<<prerequisites, 前提条件>>を満たしていることを前提としています。

これらの手順は、https://github.com/vmware-tanzu/velero-plugin-for-aws#setup[こちら]の Velero ドキュメントを元にしています。

=== 手順 1 - AWS S3 バケットの作成

[source,bash]
----
BUCKET=<YOUR_BUCKET>
REGION=<YOUR_REGION>
aws s3api create-bucket \
    --bucket $BUCKET \
    --region $REGION \
    --create-bucket-configuration LocationConstraint=$REGION
----
NOTE: `us-east-1` では、https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html#API_CreateBucket_RequestBody[[LocationConstraint]] がサポートされていません。 `us-east-1` リージョンを使用している場合、バケットの設定は省略してください。

=== 手順 2 - Velero の権限の設定

* IAM ユーザーを作成します。

[source,bash]
----
aws iam create-user --user-name velero
----

* 必要な権限を付与するポリシーをユーザー `velero` にアタッチします。

[source,bash]
----
cat > velero-policy.json <<EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:DescribeVolumes",
                "ec2:DescribeSnapshots",
                "ec2:CreateTags",
                "ec2:CreateVolume",
                "ec2:CreateSnapshot",
                "ec2:DeleteSnapshot"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:DeleteObject",
                "s3:PutObject",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}"
            ]
        }
    ]
}
EOF
----

[source,bash]
----
aws iam put-user-policy \
  --user-name velero \
  --policy-name velero \
  --policy-document file://velero-policy.json
----

* Create an access key for user `velero`:

[source,bash]
----
aws iam create-access-key --user-name velero
----

このコマンドの結果は以下のようになります。
[source,json]
----
{
  "AccessKey": {
        "UserName": "velero",
        "Status": "Active",
        "CreateDate": "2017-07-31T22:24:41.576Z",
        "SecretAccessKey": <AWS_SECRET_ACCESS_KEY>,
        "AccessKeyId": <AWS_ACCESS_KEY_ID>
  }
}
----

* Create a Velero-specific credentials file (for example, `./credentials-velero`) in your local directory, with the following contents:

[source,bash]
----
[default]
aws_access_key_id=<AWS_ACCESS_KEY_ID>
aws_secret_access_key=<AWS_SECRET_ACCESS_KEY>
----
ここで、`AWS_ACCESS_KEY_ID` プレースホルダーと `AWS_SECRET_ACCESS_KEY` プレースホルダーには、前の手順の `create-access-key` リクエストで返された値を指定します。

=== 手順 3 - Velero のインストールと起動

* 以下の `velero` `install` コマンドを実行します。 This creates a namespace called `velero` and installs all the necessary resources to run Velero.
Make sure that you pass the correct file name containing the AWS credentials that you have created in <<Step 2 - Setup permissions for Velero, Step 2>>.

NOTE: KOTS のバックアップを使用するには、https://restic.net/[restic] が必要です。 Velero のインストール時に、以下に示すように `--use-restic` フラグを設定してください。

[source, bash]
----
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.2.0 \
    --bucket $BUCKET \
    --backup-location-config region=$REGION \
    --snapshot-location-config region=$REGION \
    --secret-file ./credentials-velero \
    --use-restic \
    --wait
----

* Velero がクラスタにインストールされたら、新しい `velero` 名前空間を確認します。 以下のように、Velero デプロイと restic デーモンセットがあれば成功です。

[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----

restic はデーモンセットなので、Kubernetes クラスタ内のノード 1 つにつき 1 つの Pod が存在します。

////

* GCP SETUP *

////
== GCP での CircleCI Server 3.x のバックアップ

以下の手順は、Google Cloud Platform を対象としており、<<prerequisites, 前提条件>>を満たしていることを前提としています。

これらの手順は、https://github.com/vmware-tanzu/velero-plugin-for-gcp#setup[[こちら]]の Velero GCP プラグインのドキュメントを元にしています。

=== 手順 1 - GCP バケットの作成
To reduce the risk of typos, set some of the parameters as shell variables. すべての手順を 1 つのセッションで完了できず、再開する場合は、必要に応じて変数を再設定するようにしてください。 In the step below, for example, you will define a variable for your bucket name. Replace the `<YOUR_BUCKET>` placeholder with the name of the bucket you want to create for your backups.

[source,bash]
----
BUCKET=<YOUR_BUCKET>

gsutil mb gs://$BUCKET/
----

=== 手順 2 - Velero の権限の設定

CircleCI Server を GKE クラスタ内で実行している場合、RBAC オブジェクトを作成する必要があるため、使用する IAM ユーザーをクラスタの管理者に設定してください。 詳細については、https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control#iam-rolebinding-bootstrap[[GKE のドキュメント]]を参照してください。

. First, set a shell variable for your project ID. それにはまず、次のコマンドを実行して現在の設定を調査し、`gcloud` CLI が正しいプロジェクトを参照していることを確認します。
+
[source,bash]
----
gcloud config list
----

. If the project is correct, set the variable as follows:
+
[source,bash]
----
PROJECT_ID=$(gcloud config get-value project)
----

. 以下のコマンドを実行して、サービス アカウントを作成します。
+
[source,bash]
----
gcloud iam service-accounts create velero \
    --display-name "Velero service account"
----
NOTE: If you run several clusters with Velero, you might want to consider using a more specific name for the Service Account besides `velero`, as suggested in the example above.

. 以下のコマンドを実行して、サービス アカウントが正常に作成されたことを確認します。
+
[source,bash]
----
gcloud iam service-accounts list
----

. 次に、サービス アカウントの電子メール アドレスを変数に格納します。
+
[source,bash]
----
SERVICE_ACCOUNT_EMAIL=$(gcloud iam service-accounts list \
  --filter="displayName:Velero service account" \
  --format 'value(email)')
----
サービス アカウントに付けた表示名に合わせて、必要に応じてコマンドを変更してください。

. 必要な権限をサービス アカウントに付与します。
+
[source,bash]
----
ROLE_PERMISSIONS=(
    compute.disks.get
    compute.disks.create
    compute.disks.createSnapshot
    compute.snapshots.get
    compute.snapshots.create
    compute.snapshots.useReadOnly
    compute.snapshots.delete
    compute.zones.get
)

gcloud iam roles create velero.server \
    --project $PROJECT_ID \
    --title "Velero Server" \
    --permissions "$(IFS=","; echo "${ROLE_PERMISSIONS[*]}")"

gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member serviceAccount:$SERVICE_ACCOUNT_EMAIL \
    --role projects/$PROJECT_ID/roles/velero.server

gsutil iam ch serviceAccount:$SERVICE_ACCOUNT_EMAIL:objectAdmin gs://${BUCKET}
----

次に、Velero でこのサービス アカウントを使用できるようにする必要があります。

==== オプション 1: JSON キー ファイル

サービス アカウントとしてアクションを実行できるように Velero を認証するには、JSON 認証情報ファイルを Velero に渡します。 それにはまず、以下のコマンドを実行してキーを作成します。
[source,bash]
----
gcloud iam service-accounts keys create credentials-velero \
    --iam-account $SERVICE_ACCOUNT_EMAIL
----
After running this command, you should see a file named `credentials-velero` in your local working directory.

==== オプション 2: Workload Identity

If you are already using https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity[Workload Identities] in your cluster, you can bind the GCP Service Account you just created to Velero's Kubernetes service account. In this case, the GCP Service Account needs the
`iam.serviceAccounts.signBlob` role in addition to the permissions already specified above.

=== 手順 3 - Velero のインストールと起動

* サービス アカウントの認証方法に応じて、以下の `velero` `install` コマンドのいずれかを実行します。 This creates a namespace called `velero` and installs all the necessary resources to run Velero.

NOTE: KOTS のバックアップを使用するには、 https://restic.net/[restic] が必要です。 Velero のインストール時に、`--use-restic` フラグを設定してください。

==== JSON キー ファイルを使用する場合

[source, bash]
----
velero install \
    --provider gcp \
    --plugins velero/velero-plugin-for-gcp:v1.2.0 \
    --bucket $BUCKET \
    --secret-file ./credentials-velero \
    --use-restic \
    --wait
----

==== Workload Identity を使用する場合

[source,bash]
----
velero install \
    --provider gcp \
    --plugins velero/velero-plugin-for-gcp:v1.2.0 \
    --bucket $BUCKET \
    --no-secret \
    --sa-annotations iam.gke.io/gcp-service-account=$SERVICE_ACCOUNT_EMAIL \
    --backup-location-config serviceAccount=$SERVICE_ACCOUNT_EMAIL \
    --use-restic \
    --wait
----

システムをカスタマイズする他のオプションについては、https://github.com/vmware-tanzu/velero-plugin-for-gcp#install-and-start-velero[[Velero のドキュメント]]を参照してください。

* Velero がクラスタにインストールされたら、新しい `velero` 名前空間を確認します。 以下のように、Velero デプロイと restic デーモンセットがあれば成功です。

[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----

restic はデーモンセットなので、Kubernetes クラスタ内のノード 1 つにつき 1 つの Pod が存在します。

////

* S3-COMPATIBLE SETUP *

////
== Server 3.x backups with S3-compatible storage

以下の手順では、S3 互換オブジェクトストレージ (AWS S3 に限らない) をバックアップに使用していることが前提です。
また、<<s3-compatible-storage-prerequisites, 前提条件>>を満たしていることも前提としています。

これらの手順は、https://velero.io/docs/v1.6/contributions/minio/[こちら] の Velero ドキュメントを元にしています。

=== 手順 1 - `mc` クライアントの設定

最初に、ストレージ プロバイダーに接続できるよう https://docs.min.io/minio/baremetal/reference/minio-mc.html[`mc`] を設定します。

[source,bash]
----
# エイリアスは任意の名前でかまいませんが、以降のコマンドでも同じ値を使用してください。
export ALIAS=my-provider
mc alias set $ALIAS <YOUR_MINIO_ENDPOINT> <YOUR_MINIO_ACCESS_KEY_ID> <YOUR_MINIO_SECRET_ACCESS_KEY>
----

クライアントが適切に設定されたかどうかは、`mc ls my-provider` を実行して確認できます。

=== 手順 2 - バケットの作成

バックアップ用のバケットを作成します。 It is important that a new bucket is used, as Velero cannot use an existing bucket that already contains other content.

[source, bash]
----
mc mb ${ALIAS}/<YOUR_BUCKET>
----

=== 手順 3 - ユーザーとポリシーの作成

次に、Velero がバケットにアクセスするためのユーザーとポリシーを作成します。

NOTE: In the following snippet `<YOUR_MINIO_ACCESS_KEY_ID>` and `<YOUR_MINIO_SECRET_ACCESS_KEY>` refer to the credentials used by Velero to access MinIO.

[source, bash]
----
# ユーザーを作成します。
mc admin user add $ALIAS <YOUR_MINIO_ACCESS_KEY_ID> <YOUR_MINIO_SECRET_ACCESS_KEY>

# ポリシーを作成します。
cat > velero-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:*"
      ],
      "Resource": [
        "arn:aws:s3:::<YOUR_BUCKET>",
        "arn:aws:s3:::<YOUR_BUCKET>/*"
      ]
    }
  ]
}
EOF

mc admin policy add $ALIAS velero-policy velero-policy.json

# ユーザーをポリシーにバインド
mc admin policy set $ALIAS velero-policy user=<YOUR_VELERO_ACCESS_KEY_ID>
----

Finally, add your new user's credentials to a file (`./credentials-velero` in this example) with the following contents:

[source,toml]
----
[default]
aws_access_key_id=<YOUR_VELERO_ACCESS_KEY_ID>
aws_secret_access_key=<YOUR_VELERO_SECRET_ACCESS_KEY>
----

=== 手順 4 - Velero のインストールと起動

以下の `velero install` コマンドを実行します。 This creates a namespace called `velero` and installs all the necessary resources to run Velero.

NOTE: KOTS のバックアップを使用するには、https://restic.net/[restic] が必要です。 Velero のインストール時に、以下に示すように `--use-restic` フラグセットを設定してください。

[source, bash]
----
velero install --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.2.0 \
  --bucket <YOUR_BUCKET> \
  --secret-file ./credentials-velero \
  --use-volume-snapshots=false \
  --use-restic \
  --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=<YOUR_ENDPOINT> \
  --wait
----

Velero がクラスタにインストールされたら、新しい `velero` 名前空間を確認します。 以下のように、Velero デプロイと restic デーモンセットがあれば成功です。

[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----

restic はデーモンセットなので、Kubernetes クラスタ内のノード 1 つにつき 1 つの Pod が存在します。

== バックアップの作成
Now that Velero is installed on your cluster, you should see the **Snapshots** option in the navbar of the management console.

image::kots-admin-navbar-snapshot-option.png[KOTS Navbar]

このオプションが表示されれば、バックアップの作成を始める準備は完了です。 このオプションが表示されない場合は、<<troubleshooting-backups-and-restoration, トラブルシューティングに関するセクション>>を参照してください。

=== Option 1 - Create a backup with KOTS CLI

バックアップを作成するには、以下を実行します。

[source,bash]
----
kubectl kots backup --namespace <your namespace>
----

=== オプション 2 - KOTS 管理者コンソールを使用したバックアップ作成

ナビゲーション バーの *[Snapshots (スナップショット)]* を選択します。 デフォルトでは *[Full Snapshots (フル スナップショット)]* が選択されています。 これが推奨オプションです。

image::kots-admin-full-snapshot.png[KOTS Navbar]

*[Start a snapshot (スナップショットの開始)]* ボタンをクリックします。

image::kots-admin-create-backup.png[KOTS Create Snapshot]

== バックアップの復元

=== オプション 1 - スナップショットからのバックアップ復元

To restore from a backup stored in your S3-compatible storage, you need to ensure Velero is installed on your Kubernetes cluster and that Velero has access to the storage bucket containing the backups. When using EKS, restoring CircleCI server requires that an instance of CircleCI server is installed beforehand. When using GKE or other platforms, a cluster with just Velero installed may work.  

NOTE: If this is a new cluster or if you need to reinstall Velero, the installation should be done with the same credentials generated above.

=== Option 2 - Restore a backup using the KOTS CLI

To restore a backup using the KOTS CLI, run the following command to get a list of backups:

[source,bash]
----
kubectl kots get backups
----

復元プロセスを開始するには、前述のコマンドで取得したバックアップ名を使用して、以下のコマンドを実行します。

[source,bash]
----
kubectl kots restore --from-backup <backup-instance-id>
----

=== Option 3 - Restore a backup using the KOTS Admin Console

As with backups, navigate to *Snapshots* in the KOTS Admin Console. 今回は、復元アイコン付きのバックアップがすべて表示されます。
使用するバックアップを選択し、復元アイコンを選択します。
使用するバックアップを選択し、復元を選択します。

image::kots-admin-restore.png[KOTS Create Snapshot]

IMPORTANT: 復元すると、CircleCI サービス用に新しいロード バランサーが作成されます。 Consequently, you will need to either update your DNS records or the hostname/IP configurations in KOTS Admin Console. You may also need to consider updating the `nomad server endpoint` provided to your Nomad clients.

IMPORTANT: If you are using pre-existing Nomad clients, you need to restart them before they will connect to the nomad-server cluster.

It should take approximately 10-15 mins for CircleCI server to be restored and operational.

== Optional - Scheduling backups with KOTS

To schedule regular backups, select *Snapshots*, and then *Settings & Schedule* from the KOTS Admin Console.

image::kots-admin-scheduled-backup.png[Snapshots Selected]

And here you can find configurations related to your snapshots, including scheduling.

image::kots-admin-scheduled-snapshots.png[Snapshot Settings]

== バックアップと復元のトラブルシューティング

=== Snapshots are not available in KOTS Admin Console

If your KOTS Admin Console does not display the snapshot option, you may try the following:

* Confirm that your version of KOTS supports snapshots. 現時点では、v1.40.0 以上が推奨されます。

```
$ kubectl kots version
Replicated KOTS 1.40.0
```

* Velero がデプロイされ、適切に動作していることを確認します。 You may check the Velero logs with the following command:

```
$ kubectl logs deployment/velero --namespace velero
```

You may need to reinstall Velero afterwards.

* お使いのライセンスでスナップショットを利用できることを確認します。 You may contact our Customer Support Team for confirmation.

=== バックアップ プロセスまたは復元プロセスでエラーが発生した

バックアップまたは復元プロセスでエラーが発生した場合は、まず Velero ログを確認してください。
上記のコマンドの結果 4XX エラーが見つかった場合、ストレージ バケットへのアクセスの問題が原因の可能性があります。

* バケットが存在していることと、想定するリージョンにあることを確認します。
* Confirm that the credentials provided to Velero can be used to access the bucket.
* You may need to run the command to install Velero again, this time with updated bucket information.

You may also check the status of pods in the `velero` namespace:

```
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Pending   0          10m
restic-94ptv              1/1     Running   0          10m
restic-ch6m9              1/1     Pending   0          10m
restic-mknws              1/1     Running   0          10m
velero-68788b675c-dm2s7   1/1     Running   0          10m
```

In the above example, some restic pods are pending, which means they are waiting for a node to have available CPU or memory resources. In this case, you may need to scale your nodes to accommodate restic.
